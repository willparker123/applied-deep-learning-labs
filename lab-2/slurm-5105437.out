0it [00:00, ?it/s]  0%|          | 0/170498071 [00:00<?, ?it/s]  0%|          | 40960/170498071 [00:00<12:27, 227934.07it/s]  0%|          | 221184/170498071 [00:01<09:34, 296221.09it/s]  1%|          | 909312/170498071 [00:01<06:54, 409466.45it/s]  1%|▏         | 2498560/170498071 [00:01<04:50, 578557.86it/s]  3%|▎         | 5775360/170498071 [00:01<03:20, 820303.82it/s]  5%|▌         | 9281536/170498071 [00:01<02:18, 1160228.37it/s]  7%|▋         | 12673024/170498071 [00:01<01:36, 1633519.11it/s]  9%|▉         | 15867904/170498071 [00:01<01:07, 2283493.96it/s] 11%|█▏        | 19390464/170498071 [00:01<00:47, 3173441.50it/s] 14%|█▎        | 23076864/170498071 [00:01<00:33, 4371961.34it/s] 16%|█▌        | 26451968/170498071 [00:01<00:24, 5901553.75it/s] 17%|█▋        | 29827072/170498071 [00:02<00:17, 7842865.00it/s] 19%|█▉        | 33234944/170498071 [00:02<00:13, 10197928.15it/s] 22%|██▏       | 36757504/170498071 [00:02<00:10, 12283655.11it/s] 24%|██▎       | 40394752/170498071 [00:02<00:08, 15318802.27it/s] 26%|██▌       | 44015616/170498071 [00:02<00:06, 18522364.93it/s] 28%|██▊       | 47521792/170498071 [00:02<00:05, 21564152.18it/s] 30%|██▉       | 50896896/170498071 [00:02<00:04, 24135843.21it/s] 32%|███▏      | 54263808/170498071 [00:02<00:04, 26372263.33it/s] 34%|███▍      | 57860096/170498071 [00:02<00:03, 28194521.10it/s] 36%|███▌      | 61472768/170498071 [00:03<00:03, 30182238.20it/s] 38%|███▊      | 64913408/170498071 [00:03<00:03, 31294609.33it/s] 40%|████      | 68354048/170498071 [00:03<00:03, 31791014.67it/s] 42%|████▏     | 71835648/170498071 [00:03<00:03, 32634145.29it/s] 44%|████▍     | 75505664/170498071 [00:03<00:02, 33435398.71it/s] 46%|████▋     | 78970880/170498071 [00:03<00:02, 33633046.35it/s] 48%|████▊     | 82550784/170498071 [00:03<00:02, 34244605.60it/s] 51%|█████     | 86450176/170498071 [00:03<00:02, 31227439.73it/s] 53%|█████▎    | 90251264/170498071 [00:03<00:02, 32993407.48it/s] 55%|█████▌    | 93921280/170498071 [00:04<00:02, 33971494.36it/s] 57%|█████▋    | 97476608/170498071 [00:04<00:02, 34427293.18it/s] 59%|█████▉    | 101212160/170498071 [00:04<00:01, 35255835.70it/s] 62%|██████▏   | 104898560/170498071 [00:04<00:01, 35717054.12it/s] 64%|██████▎   | 108535808/170498071 [00:04<00:01, 35911020.79it/s] 66%|██████▌   | 112254976/170498071 [00:04<00:01, 36277188.16it/s] 68%|██████▊   | 115900416/170498071 [00:04<00:01, 36263670.36it/s] 70%|███████   | 119545856/170498071 [00:04<00:01, 36261358.75it/s] 72%|███████▏  | 123183104/170498071 [00:04<00:01, 35473856.55it/s] 74%|███████▍  | 126967808/170498071 [00:04<00:01, 36153008.97it/s] 77%|███████▋  | 130596864/170498071 [00:05<00:01, 36100333.28it/s] 79%|███████▊  | 134217728/170498071 [00:05<00:01, 36088643.17it/s] 81%|████████  | 137838592/170498071 [00:05<00:00, 35929812.55it/s] 83%|████████▎ | 141615104/170498071 [00:05<00:00, 33446833.06it/s] 85%|████████▌ | 145367040/170498071 [00:05<00:00, 34568042.70it/s] 87%|████████▋ | 148905984/170498071 [00:05<00:00, 34802115.05it/s] 89%|████████▉ | 152412160/170498071 [00:05<00:00, 34734610.50it/s] 92%|█████████▏| 156114944/170498071 [00:05<00:00, 35389416.66it/s] 94%|█████████▎| 159670272/170498071 [00:05<00:00, 35206574.96it/s] 96%|█████████▌| 163209216/170498071 [00:05<00:00, 35065946.85it/s] 98%|█████████▊| 166731776/170498071 [00:06<00:00, 34736897.96it/s]100%|█████████▉| 170385408/170498071 [00:06<00:00, 35232942.20it/s]170500096it [00:06, 27630349.65it/s]                               Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /mnt/storage/home/gg18045/.cache/torch/datasets/cifar-10-python.tar.gz
Extracting /mnt/storage/home/gg18045/.cache/torch/datasets/cifar-10-python.tar.gz to /mnt/storage/home/gg18045/.cache/torch/datasets
Writing logs to logs/CNN_bs=128_lr=0.01_run_0

Traceback (most recent call last):
  File "lab-2.py", line 361, in <module>
    main(parser.parse_args())
  File "lab-2.py", line 137, in main
    log_frequency=args.log_frequency,
  File "lab-2.py", line 233, in train
    logits = self.model.forward(batch)
  File "lab-2.py", line 179, in forward
    x = F.relu(self.conv2(x))
  File "/mnt/storage/software/languages/anaconda/Anaconda3-2019.07/lib/python3.7/site-packages/torch/nn/modules/module.py", line 547, in __call__
    result = self.forward(*input, **kwargs)
  File "/mnt/storage/software/languages/anaconda/Anaconda3-2019.07/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 343, in forward
    return self.conv2d_forward(input, self.weight)
  File "/mnt/storage/software/languages/anaconda/Anaconda3-2019.07/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 340, in conv2d_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Given groups=1, weight of size 64 3 5 5, expected input[128, 32, 16, 16] to have 3 channels, but got 32 channels instead
